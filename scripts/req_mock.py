#!/usr/bin/env python3
# /// script
# requires-python = ">=3.13"
# dependencies = [
#     "aiohttp",
# ]
# ///
"""
å¹¶å‘è¯·æ±‚æµ‹è¯•è„šæœ¬
å‘é€å¹¶å‘è¯·æ±‚åˆ° http://localhost:8080/user?id=<random_id>
"""

import asyncio
import aiohttp
import random
import time
import argparse
from typing import Dict, List
import json


class RequestStats:
    """è¯·æ±‚ç»Ÿè®¡ç±»"""
    def __init__(self):
        self.total_requests = 0
        self.successful_requests = 0
        self.failed_requests = 0
        self.response_times = []
        self.errors = []
    
    def add_success(self, response_time: float):
        self.total_requests += 1
        self.successful_requests += 1
        self.response_times.append(response_time)
    
    def add_failure(self, error: str, response_time: float = 0):
        self.total_requests += 1
        self.failed_requests += 1
        self.errors.append(error)
        if response_time > 0:
            self.response_times.append(response_time)
    
    def get_summary(self) -> Dict:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        if self.response_times:
            avg_response_time = sum(self.response_times) / len(self.response_times)
            min_response_time = min(self.response_times)
            max_response_time = max(self.response_times)
        else:
            avg_response_time = min_response_time = max_response_time = 0
        
        return {
            "total_requests": self.total_requests,
            "successful_requests": self.successful_requests,
            "failed_requests": self.failed_requests,
            "success_rate": (self.successful_requests / self.total_requests * 100) if self.total_requests > 0 else 0,
            "avg_response_time_ms": round(avg_response_time * 1000, 2),
            "min_response_time_ms": round(min_response_time * 1000, 2),
            "max_response_time_ms": round(max_response_time * 1000, 2),
            "errors": self.errors[:10]  # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
        }


async def make_request(session: aiohttp.ClientSession, base_url: str, stats: RequestStats, 
                      min_id: int = 1, max_id: int = 10000) -> None:
    """å‘é€å•ä¸ªè¯·æ±‚"""
    user_id = random.randint(min_id, max_id)
    url = f"{base_url}/user?id={user_id}"
    
    start_time = time.time()
    try:
        async with session.get(url) as response:
            end_time = time.time()
            response_time = end_time - start_time
            
            # è¯»å–å“åº”å†…å®¹
            content = await response.text()
            
            if response.status == 200:
                stats.add_success(response_time)
                print(f"âœ“ ID:{user_id} Status:{response.status} Time:{response_time*1000:.2f}ms")
            else:
                error_msg = f"HTTP {response.status}: {content[:100]}"
                stats.add_failure(error_msg, response_time)
                print(f"âœ— ID:{user_id} Status:{response.status} Time:{response_time*1000:.2f}ms Error:{content[:50]}")
                
    except aiohttp.ClientError as e:
        end_time = time.time()
        response_time = end_time - start_time
        error_msg = f"ClientError: {str(e)}"
        stats.add_failure(error_msg, response_time)
        print(f"âœ— ID:{user_id} ClientError: {e}")
    except Exception as e:
        end_time = time.time()
        response_time = end_time - start_time
        error_msg = f"Exception: {str(e)}"
        stats.add_failure(error_msg, response_time)
        print(f"âœ— ID:{user_id} Exception: {e}")


async def run_concurrent_requests(base_url: str, num_requests: int, concurrency: int,
                                 min_id: int = 1, max_id: int = 10000) -> RequestStats:
    """è¿è¡Œå¹¶å‘è¯·æ±‚"""
    stats = RequestStats()
    
    # åˆ›å»ºè¿æ¥æ± 
    connector = aiohttp.TCPConnector(limit=concurrency, limit_per_host=concurrency)
    timeout = aiohttp.ClientTimeout(total=30)  # 30ç§’è¶…æ—¶
    
    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        # åˆ›å»ºä¿¡å·é‡æ¥æ§åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(concurrency)
        
        async def bounded_request():
            async with semaphore:
                await make_request(session, base_url, stats, min_id, max_id)
        
        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [bounded_request() for _ in range(num_requests)]
        
        print(f"å¼€å§‹å‘é€ {num_requests} ä¸ªå¹¶å‘è¯·æ±‚ (å¹¶å‘åº¦: {concurrency})...")
        print(f"ç›®æ ‡URL: {base_url}/user?id=<{min_id}-{max_id}>")
        print("-" * 80)
        
        start_time = time.time()
        
        # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        print("-" * 80)
        print(f"æ‰€æœ‰è¯·æ±‚å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}s")
        
        # è®¡ç®—QPS
        qps = num_requests / total_time if total_time > 0 else 0
        print(f"QPS (æ¯ç§’è¯·æ±‚æ•°): {qps:.2f}")
    
    return stats


def print_statistics(stats: RequestStats):
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    summary = stats.get_summary()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š è¯·æ±‚ç»Ÿè®¡æŠ¥å‘Š")
    print("=" * 60)
    print(f"æ€»è¯·æ±‚æ•°:     {summary['total_requests']}")
    print(f"æˆåŠŸè¯·æ±‚æ•°:   {summary['successful_requests']}")
    print(f"å¤±è´¥è¯·æ±‚æ•°:   {summary['failed_requests']}")
    print(f"æˆåŠŸç‡:       {summary['success_rate']:.2f}%")
    print(f"å¹³å‡å“åº”æ—¶é—´: {summary['avg_response_time_ms']:.2f}ms")
    print(f"æœ€å°å“åº”æ—¶é—´: {summary['min_response_time_ms']:.2f}ms")
    print(f"æœ€å¤§å“åº”æ—¶é—´: {summary['max_response_time_ms']:.2f}ms")
    
    if summary['errors']:
        print(f"\nâŒ é”™è¯¯ä¿¡æ¯ (æ˜¾ç¤ºå‰10ä¸ª):")
        for i, error in enumerate(summary['errors'], 1):
            print(f"  {i}. {error}")
    
    print("=" * 60)


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¹¶å‘è¯·æ±‚æµ‹è¯•å·¥å…·")
    parser.add_argument("--url", default="http://localhost:8080", 
                       help="åŸºç¡€URL (é»˜è®¤: http://localhost:8080)")
    parser.add_argument("-n", "--requests", type=int, default=200,
                       help="æ€»è¯·æ±‚æ•° (é»˜è®¤: 100)")
    parser.add_argument("-c", "--concurrency", type=int, default=100,
                       help="å¹¶å‘æ•° (é»˜è®¤: 10)")
    parser.add_argument("--min-id", type=int, default=1,
                       help="ç”¨æˆ·IDæœ€å°å€¼ (é»˜è®¤: 1)")
    parser.add_argument("--max-id", type=int, default=10000,
                       help="ç”¨æˆ·IDæœ€å¤§å€¼ (é»˜è®¤: 10000)")
    parser.add_argument("--json-output", action="store_true",
                       help="ä»¥JSONæ ¼å¼è¾“å‡ºç»“æœ")
    
    args = parser.parse_args()
    
    # éªŒè¯å‚æ•°
    if args.requests <= 0:
        print("âŒ è¯·æ±‚æ•°å¿…é¡»å¤§äº0")
        return
    
    if args.concurrency <= 0:
        print("âŒ å¹¶å‘æ•°å¿…é¡»å¤§äº0")
        return
    
    if args.min_id >= args.max_id:
        print("âŒ æœ€å°IDå¿…é¡»å°äºæœ€å¤§ID")
        return
    
    try:
        # è¿è¡Œå¹¶å‘è¯·æ±‚
        stats = await run_concurrent_requests(
            args.url, args.requests, args.concurrency, args.min_id, args.max_id
        )
        
        if args.json_output:
            # JSONæ ¼å¼è¾“å‡º
            result = stats.get_summary()
            print(json.dumps(result, indent=2, ensure_ascii=False))
        else:
            # æ™®é€šæ ¼å¼è¾“å‡º
            print_statistics(stats)
            
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­è¯·æ±‚")
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    # è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥ (Windowså…¼å®¹æ€§)
    try:
        if hasattr(asyncio, 'WindowsProactorEventLoopPolicy'):
            asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    except:
        pass
    
    asyncio.run(main())
